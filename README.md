# ChemFetch

> **Automated Chemical Register & SDS (Safety Data Sheet) Management Platform**

ChemFetch turns a **barcode scan** into a fully‑populated hazardous‑chemical record with the **current SDS**, hazard & transport (DG) data, site‑specific quantity/location, and a configurable risk‑assessment layer that respects five‑year SDS review rules.

---

## Table of Contents

1. Vision & Problem
2. Core Value Proposition
3. Key Features
4. Architecture Overview
5. Technology Stack Rationale
6. Data & Domain Model Summary
7. Parsing / Extraction Pipeline
8. Risk Assessment Model
9. Repository Structure
10. **Prerequisites & Getting Started**
11. Workflow: From Scan to Register
12. Roadmap & Phases
13. Quality, Metrics & Monitoring
14. Security & Compliance
15. Contribution Guidelines
16. License
17. References

---

## 1. Vision & Problem

Workplaces must maintain an accessible, up‑to‑date register of hazardous chemicals with a current SDS for each product. Australian WHS regulation mandates SDS review at least every **five years** and requires the review date to be visible (typically in Section 16). Paper binders and spreadsheets quickly fall out‑of‑date, risking non‑compliance and worker confusion.

## 2. Core Value Proposition

ChemFetch eliminates manual upkeep by:

- Scanning a GTIN/EAN/UPC barcode to uniquely identify a product.
- Fetching or uploading the SDS PDF.
- Parsing the 16 GHS sections to extract hazard & transport fields.
- Normalising data for search, export, and analytics.
- Computing site‑specific risk ratings (consequence × likelihood).
- Monitoring SDS currency with automated alerts before the 5‑year expiry.

## 3. Key Features

- **Barcode → Product Resolution:** Prevent duplicate entries with GTIN uniqueness.
- **SDS Versioning & Currency Tracking:** Flag “current”, “expiring soon”, and “superseded” based on issue date.
- **16‑Section Extraction:** Structured hazard vs transport (DG) data for reporting & search.
- **Risk Assessment Layer:** Site controls separated from intrinsic SDS hazard classification.
- **Async Parsing Pipeline:** Celery workers scale horizontally; confidence scoring gates human review.
- **Developer‑Friendly API:** FastAPI endpoints with autogenerated OpenAPI/Swagger and JSON Schema.

## 4. Architecture Overview

| Layer              | Responsibility                      | Technology                                                |
| ------------------ | ----------------------------------- | --------------------------------------------------------- |
| **API**            | Auth, RBAC, CRUD, WebSockets        | **FastAPI (Python 3.11)** + Uvicorn/Gunicorn‑UVLoop       |
| **Async Tasks**    | SDS fetch, parsing, expiry alerts   | **Celery 5** + Redis / RabbitMQ                           |
| **Scheduler**      | Recurring jobs                      | Celery Beat                                               |
| **Database**       | Normalised schema, full‑text search | PostgreSQL 15 (pg\_trgm)                                  |
| **Object Storage** | Durable SDS PDFs & artefacts        | S3‑compatible (AWS S3 / MinIO)                            |
| **Parsing / OCR**  | Text & layout extraction            | pdfplumber, Camelot, Tesseract, Deepdoctection/LayoutLMv3 |

## 5. Technology Stack Rationale

- **Single‑language stack:** Python 3.11 across API and workers eliminates context‑switching.
- **FastAPI:** Async I/O, type hints, dependency injection, and automatic OpenAPI docs.
- **Celery 5 + Celery Beat:** Mature task queue with retry & schedule support, aligning with Python ecosystem.
- **pdfplumber + Tesseract:** Proven open‑source tooling for machine PDFs and scanned documents.
- **PostgreSQL 15:** Robust relational store with extension support for fuzzy search (pg\_trgm) and composite GIN indexes.

## 6. Data & Domain Model Summary

Core entities: **Product**, **SDSDocument** (versioned), **HazardClassification** (Section 2), **TransportInfo** (Section 14), **SiteChemical**, **RiskAssessment**, **RiskMatrix**, **FileAsset**, **AuditLog**, **Notification**.

## 7. Parsing / Extraction Pipeline

Ingestion → PDF/Text classification → Native text extraction or OCR → Section segmentation → Table extraction → Field normalisation → Confidence scoring → Persistence → Alerts.

## 8. Risk Assessment Model

Risk = Consequence × Likelihood matrix; critical hazards or high ratings auto‑flag Safe Work Procedure (SWP) requirements.

## 9. Repository Structure (Proposed)

```text
chemfetch/
  pyproject.toml
  README.md
  src/
    chemfetch/api/            # FastAPI routers
    chemfetch/models/         # Pydantic & SQLModel schemas
    chemfetch/db/             # DB session & migrations
    chemfetch/parsing/        # pdfplumber + OCR integration
    chemfetch/tasks/          # Celery tasks (fetch, parse, alerts)
    chemfetch/services/       # Business logic (versioning, risk)
    chemfetch/notifications/  # Email / webhook alerts
    chemfetch/config/         # Settings via Pydantic BaseSettings
  tests/
  docker/
  infra/                      # Terraform / Compose files
```

## 10. Prerequisites & Getting Started

### Prerequisites

- **Python ≥ 3.11** (CPython)
- PostgreSQL 15
- Redis 7 (or RabbitMQ 3.13) for Celery broker
- Make / Docker Compose (optional but recommended)

### Quick Start (Poetry)

```bash
# Clone & set up
poetry env use 3.11
poetry install

# Run DB migrations
poetry run alembic upgrade head

# Start API (reload)
poetry run uvicorn chemfetch.api.main:app --host 0.0.0.0 --port 8000 --reload

# Start Celery worker & scheduler
poetry run celery -A chemfetch.tasks.app worker -l info &
poetry run celery -A chemfetch.tasks.app beat -l info &
```

Alternatively, use **Docker Compose** (`docker compose up --build`) to start API, worker, scheduler, Postgres, and Redis containers.

## 11. Workflow: From Scan to Register

1. **Scan Barcode:** Mobile client decodes GTIN and calls `/products/lookup`; unmatched codes trigger product creation.
2. **SDS Acquisition:** Upload or provide URL; system stores file & enqueues extraction task.
3. **Parsing & OCR:** pdfplumber extracts text; Tesseract OCR path for image‑only pages.
4. **Field Extraction:** Hazard statements, pictograms, transport table captured.
5. **Version & Currency Check:** Issue date sets `current`, supersedes older SDS, and drives expiry alerts.
6. **Risk Assessment:** Site consequence & likelihood produce rating; SWP flag set if threshold exceeded.
7. **Register Export:** API delivers CSV/Excel or JSON for audits.

## 12. Roadmap & Phases

1. **Phase 0 – Environment Hardening:** lock Python 3.11, pre‑commit, Dockerfile.
2. **Phase 1 – MVP:** Barcode API, manual SDS upload, basic parsing, register export.
3. **Phase 2:** Section 2 & 14 extraction, risk matrix UI, expiry alerts.
4. **Phase 3:** Confidence scoring, validation queue.
5. **Phase 4:** Analytics & jurisdiction profiles.
6. **Phase 5:** Third‑party EHS API integrations.

## 13. Quality, Metrics & Monitoring

Metrics: parsing accuracy (issue date, UN number), OCR fallback rate, SDS currency %, queue latency, median scan→register time. FastAPI & Celery expose Prometheus metrics; Loki/Grafana dashboards recommended.

## 14. Security & Compliance

- Pre‑signed S3 URLs for SDS downloads.
- SHA‑256 hash on upload; immutable storage tier.
- AuditLog captures every create/update/view.
- Secrets managed via `.env` or Docker secrets.
- Role‑based scopes enforced via FastAPI dependencies and JWT claims.

## 15. Contribution Guidelines

- Follow **conventional commits**.
- Include unit tests & fixtures for extraction logic.
- Run `ruff`, `mypy`, and `pytest` locally before PR.
- Provide anonymised SDS samples when adding new parsing heuristics.

## 16. License

Recommendation: **Apache 2.0** (permissive) – final decision pending legal review.

## 17. References

Safe Work Australia, OSHA, GS1, FastAPI docs, Celery docs, pdfplumber, Tesseract, Deepdoctection, PostgreSQL docs.

---



